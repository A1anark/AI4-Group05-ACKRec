"""
ACKRecæ¨èç³»ç»Ÿ - Streamlitç•Œé¢
ä¸»åº”ç”¨ç¨‹åºæ–‡ä»¶
"""

import streamlit as st
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys
import warnings

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ACKRec - çŸ¥è¯†æ¦‚å¿µæ¨èç³»ç»Ÿ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
sys.path.append('./models')
sys.path.append('./utils')

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #424242;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .success-message {
        color: #28a745;
        font-weight: bold;
    }
    .warning-message {
        color: #ffc107;
        font-weight: bold;
    }
    .error-message {
        color: #dc3545;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# é¡µé¢æ ‡é¢˜
st.markdown('<h1 class="main-header">ğŸ“ ACKRec - çŸ¥è¯†æ¦‚å¿µæ¨èç³»ç»Ÿ</h1>', unsafe_allow_html=True)
st.markdown("### åŸºäºæ³¨æ„åŠ›å›¾å·ç§¯ç½‘ç»œçš„MOOCsçŸ¥è¯†æ¦‚å¿µæ¨èç³»ç»Ÿ")

# ä¾§è¾¹æ é…ç½®
st.sidebar.markdown('<h2 class="sub-header">âš™ï¸ é…ç½®</h2>', unsafe_allow_html=True)

# 1. æ¨¡å‹é€‰æ‹©
st.sidebar.markdown("#### æ¨¡å‹è®¾ç½®")
use_gpu = st.sidebar.checkbox("ä½¿ç”¨GPUåŠ é€Ÿ", value=torch.cuda.is_available())
model_path = st.sidebar.text_input("æ¨¡å‹è·¯å¾„", value="./saved_models/best_model.pth")

# 2. æ•°æ®è®¾ç½®
st.sidebar.markdown("#### æ•°æ®è®¾ç½®")
data_dir = st.sidebar.selectbox(
    "æ•°æ®ç›®å½•",
    options=['./data', './processed_data', './test_data'],
    index=0
)

# 3. è¯„ä¼°è®¾ç½®
st.sidebar.markdown("#### è¯„ä¼°è®¾ç½®")
k_values = st.sidebar.multiselect(
    "Top-Kè¯„ä¼°",
    options=[1, 5, 10, 20],
    default=[1, 5, 10, 20]
)

# 4. ç³»ç»Ÿä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.markdown("#### ç³»ç»Ÿä¿¡æ¯")
st.sidebar.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
st.sidebar.info(f"CUDAå¯ç”¨: {'æ˜¯' if torch.cuda.is_available() else 'å¦'}")
if torch.cuda.is_available():
    st.sidebar.info(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")

# ä¸»ç•Œé¢æ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  æ¦‚è§ˆ", "ğŸ” æ•°æ®æ¢ç´¢", "ğŸ¤– æ¨¡å‹æ¨ç†", "ğŸ“Š æ€§èƒ½è¯„ä¼°"])

with tab1:
    st.markdown('<h2 class="sub-header">ç³»ç»Ÿæ¦‚è§ˆ</h2>', unsafe_allow_html=True)
    
    # ç³»ç»Ÿä»‹ç»
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ç³»ç»Ÿç‰¹ç‚¹
        
        - **å¼‚æ„å›¾å·ç§¯**: èåˆå¤šç§ç±»å‹çš„å®ä½“å’Œå…³ç³»
        - **æ³¨æ„åŠ›æœºåˆ¶**: è‡ªé€‚åº”èåˆä¸åŒå…ƒè·¯å¾„çš„ä¿¡æ¯
        - **ç«¯åˆ°ç«¯è®­ç»ƒ**: ä»åŸå§‹æ•°æ®åˆ°æ¨èç»“æœçš„å…¨æµç¨‹
        - **å¤šç»´åº¦è¯„ä¼°**: HR@K, NDCG@K, MRR, AUCç­‰æŒ‡æ ‡
        - **å¯è§†åŒ–ç•Œé¢**: äº¤äº’å¼çš„æ¨¡å‹ç®¡ç†å’Œç»“æœå±•ç¤º
        
        ### æ ¸å¿ƒç»„ä»¶
        
        1. **GraphConvolution** - å›¾å·ç§¯å±‚
        2. **SimpleAttLayer** - æ³¨æ„åŠ›å±‚
        3. **RateLayer** - è¯„åˆ†å±‚
        4. **GCN** - å›¾å·ç§¯ç½‘ç»œ
        5. **AGCNrec** - å®Œæ•´çš„æ¨èæ¨¡å‹
        """)
    
    with col2:
        # ç³»ç»ŸçŠ¶æ€å¡ç‰‡
        st.markdown("### ç³»ç»ŸçŠ¶æ€")
        
        col2_1, col2_2, col2_3 = st.columns(3)
        
        with col2_1:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            model_exists = os.path.exists(model_path)
            if model_exists:
                st.success("âœ… æ¨¡å‹å°±ç»ª")
            else:
                st.warning("âš ï¸ æ¨¡å‹æœªæ‰¾åˆ°")
        
        with col2_2:
            # æ£€æŸ¥æ•°æ®ç›®å½•
            data_exists = os.path.exists(data_dir)
            if data_exists:
                st.success("âœ… æ•°æ®å°±ç»ª")
            else:
                st.warning("âš ï¸ æ•°æ®æœªæ‰¾åˆ°")
        
        with col2_3:
            # è®¾å¤‡ä¿¡æ¯
            device = "GPU" if use_gpu and torch.cuda.is_available() else "CPU"
            st.info(f"ğŸ“± {device}")
        
        # å¿«é€Ÿæ“ä½œ
        st.markdown("### å¿«é€Ÿæ“ä½œ")
        
        col2_4, col2_5 = st.columns(2)
        
        with col2_4:
            if st.button("ğŸš€ è¿è¡Œå¿«é€Ÿæµ‹è¯•", use_container_width=True):
                with st.spinner("æ­£åœ¨è¿è¡Œæµ‹è¯•..."):
                    try:
                        import subprocess
                        result = subprocess.run(
                            [sys.executable, "quick_start.py"], 
                            capture_output=True, 
                            text=True,
                            timeout=30
                        )
                        
                        if result.returncode == 0:
                            st.success("âœ… æµ‹è¯•é€šè¿‡!")
                            with st.expander("æŸ¥çœ‹æµ‹è¯•è¾“å‡º"):
                                st.code(result.stdout)
                        else:
                            st.error("âŒ æµ‹è¯•å¤±è´¥")
                            with st.expander("æŸ¥çœ‹é”™è¯¯ä¿¡æ¯"):
                                st.code(result.stderr)
                    except Exception as e:
                        st.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        
        with col2_5:
            if st.button("ğŸ”§ æ•…éšœæ’æŸ¥", use_container_width=True):
                with st.spinner("æ­£åœ¨æ£€æŸ¥ç³»ç»Ÿ..."):
                    try:
                        import subprocess
                        result = subprocess.run(
                            [sys.executable, "troubleshooting.py", "2"], 
                            capture_output=True, 
                            text=True,
                            timeout=30
                        )
                        
                        with st.expander("æŸ¥çœ‹æ£€æŸ¥ç»“æœ"):
                            st.code(result.stdout)
                    except Exception as e:
                        st.error(f"æ£€æŸ¥å¤±è´¥: {e}")
    
    # ä½¿ç”¨æŒ‡å—
    st.markdown("### ä½¿ç”¨æŒ‡å—")
    
    with st.expander("ğŸ“– å¿«é€Ÿå¼€å§‹æŒ‡å—"):
        st.markdown("""
        1. **å‡†å¤‡æ•°æ®**
           - å°†æ‚¨çš„æ•°æ®æ”¾å…¥ `raw_data/` ç›®å½•
           - è¿è¡Œ `python scripts/prepare_dataset.py`
        
        2. **è®­ç»ƒæ¨¡å‹**
           - è¿è¡Œ `python scripts/train_new_dataset.py`
           - æˆ–ä½¿ç”¨Webç•Œé¢çš„è®­ç»ƒåŠŸèƒ½
        
        3. **è¯„ä¼°æ¨¡å‹**
           - åœ¨"æ€§èƒ½è¯„ä¼°"æ ‡ç­¾é¡µä¸­è¿è¡Œè¯„ä¼°
           - æŸ¥çœ‹å„é¡¹æŒ‡æ ‡ç»“æœ
        
        4. **ä½¿ç”¨æ¨è**
           - åœ¨"æ¨¡å‹æ¨ç†"æ ‡ç­¾é¡µä¸­é€‰æ‹©ç”¨æˆ·
           - ç”Ÿæˆä¸ªæ€§åŒ–æ¨è
        """)
    
    with st.expander("ğŸ“ é¡¹ç›®ç»“æ„"):
        st.code("""
        ACKRec/
        â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
        â”œâ”€â”€ models/                  # æ¨¡å‹å®šä¹‰
        â”œâ”€â”€ utils/                   # å·¥å…·å‡½æ•°
        â”œâ”€â”€ scripts/                 # è®­ç»ƒè„šæœ¬
        â”œâ”€â”€ saved_models/            # è®­ç»ƒå¥½çš„æ¨¡å‹
        â”œâ”€â”€ app.py                   # Webç•Œé¢
        â”œâ”€â”€ requirements.txt         # ä¾èµ–åŒ…
        â”œâ”€â”€ config.py                # é…ç½®æ–‡ä»¶
        â””â”€â”€ README.md                # é¡¹ç›®è¯´æ˜
        """)
    
    with st.expander("ğŸ“Š è¯„ä¼°æŒ‡æ ‡è¯´æ˜"):
        st.markdown("""
        - **HR@K (Hit Rate)**: å‘½ä¸­ç‡ï¼Œå‰Kä¸ªæ¨èä¸­æ˜¯å¦åŒ…å«ç”¨æˆ·æ„Ÿå…´è¶£çš„é¡¹ç›®
        - **NDCG@K**: å½’ä¸€åŒ–æŠ˜æŸç´¯è®¡å¢ç›Šï¼Œè€ƒè™‘æ¨èæ’åçš„è´¨é‡è¯„ä¼°
        - **MRR (Mean Reciprocal Rank)**: å¹³å‡å€’æ•°æ’åï¼Œç¬¬ä¸€ä¸ªç›¸å…³é¡¹ç›®æ’åçš„å€’æ•°å¹³å‡å€¼
        - **AUC (Area Under Curve)**: æ›²çº¿ä¸‹é¢ç§¯ï¼Œè¡¡é‡æ¨¡å‹æ•´ä½“æ’åºèƒ½åŠ›çš„æŒ‡æ ‡
        """)

with tab2:
    st.markdown('<h2 class="sub-header">æ•°æ®æ¢ç´¢</h2>', unsafe_allow_html=True)
    
    # æ•°æ®åŠ è½½é€‰é¡¹
    col1, col2 = st.columns([2, 1])
    
    with col1:
        data_source = st.radio(
            "æ•°æ®æ¥æº",
            options=["å¤„ç†åçš„æ•°æ®", "åŸå§‹æ•°æ®", "ç¤ºä¾‹æ•°æ®"],
            index=0
        )
    
    with col2:
        load_data_btn = st.button("ğŸ“Š åŠ è½½æ•°æ®", type="primary")
    
    if load_data_btn:
        try:
            with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                # å¯¼å…¥æ•°æ®å·¥å…·
                from utils.data_utils import load_data
                
                # æ ¹æ®é€‰æ‹©åŠ è½½æ•°æ®
                if data_source == "å¤„ç†åçš„æ•°æ®":
                    data_path = './processed_data'
                elif data_source == "åŸå§‹æ•°æ®":
                    data_path = './raw_data'
                    st.warning("åŸå§‹æ•°æ®éœ€è¦å…ˆå¤„ç†ï¼Œå°†å°è¯•åŠ è½½å¤„ç†åçš„æ•°æ®")
                    data_path = './processed_data'
                else:
                    data_path = './data'
                
                # åŠ è½½æ•°æ®
                rating, features_item, features_user, support_user, support_item, negative = load_data(
                    user=['uku'],
                    item=['kuk'],
                    data_dir=data_path
                )
                
                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ ({data_path})")
                
                # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
                col_info1, col_info2, col_info3 = st.columns(3)
                
                with col_info1:
                    st.metric("ç”¨æˆ·æ•°", rating.shape[0])
                
                with col_info2:
                    st.metric("ç‰©å“æ•°", rating.shape[1])
                
                with col_info3:
                    density = (rating != 0).sum().item() / (rating.shape[0] * rating.shape[1]) * 100
                    st.metric("äº¤äº’å¯†åº¦", f"{density:.2f}%")
                
                # æ•°æ®å¯è§†åŒ–
                st.markdown("### æ•°æ®å¯è§†åŒ–")
                
                # è¯„åˆ†çŸ©é˜µçƒ­åŠ›å›¾
                fig1, ax1 = plt.subplots(figsize=(10, 6))
                non_zero_mask = (rating != 0).cpu().numpy()
                ax1.spy(non_zero_mask, markersize=0.5)
                ax1.set_title("è¯„åˆ†çŸ©é˜µç¨€ç–æ¨¡å¼")
                ax1.set_xlabel("ç‰©å“ç´¢å¼•")
                ax1.set_ylabel("ç”¨æˆ·ç´¢å¼•")
                st.pyplot(fig1)
                
                # ç”¨æˆ·äº¤äº’åˆ†å¸ƒ
                fig2, ax2 = plt.subplots(figsize=(10, 4))
                user_interactions = (rating != 0).sum(dim=1).cpu().numpy()
                ax2.hist(user_interactions, bins=20, alpha=0.7, color='skyblue')
                ax2.set_title("ç”¨æˆ·äº¤äº’æ¬¡æ•°åˆ†å¸ƒ")
                ax2.set_xlabel("äº¤äº’æ¬¡æ•°")
                ax2.set_ylabel("ç”¨æˆ·æ•°é‡")
                st.pyplot(fig2)
                
                # ç‰©å“æµè¡Œåº¦åˆ†å¸ƒ
                fig3, ax3 = plt.subplots(figsize=(10, 4))
                item_popularity = (rating != 0).sum(dim=0).cpu().numpy()
                ax3.hist(item_popularity, bins=20, alpha=0.7, color='lightgreen')
                ax3.set_title("ç‰©å“è¢«äº¤äº’æ¬¡æ•°åˆ†å¸ƒ")
                ax3.set_xlabel("è¢«äº¤äº’æ¬¡æ•°")
                ax3.set_ylabel("ç‰©å“æ•°é‡")
                st.pyplot(fig3)
                
                # æ•°æ®ç»Ÿè®¡è¡¨æ ¼
                st.markdown("### è¯¦ç»†ç»Ÿè®¡")
                
                stats_data = {
                    "æŒ‡æ ‡": ["ç”¨æˆ·æ•°", "ç‰©å“æ•°", "æ€»äº¤äº’æ•°", "çŸ©é˜µå¯†åº¦", 
                           "å¹³å‡ç”¨æˆ·äº¤äº’æ•°", "å¹³å‡ç‰©å“è¢«äº¤äº’æ•°", "ç”¨æˆ·æ”¯æŒçŸ©é˜µ", "ç‰©å“æ”¯æŒçŸ©é˜µ"],
                    "å€¼": [
                        rating.shape[0],
                        rating.shape[1],
                        int((rating != 0).sum().item()),
                        f"{density:.4f}%",
                        f"{user_interactions.mean():.2f}",
                        f"{item_popularity.mean():.2f}",
                        len(support_user),
                        len(support_item)
                    ]
                }
                
                stats_df = pd.DataFrame(stats_data)
                st.dataframe(stats_df, use_container_width=True)
                
        except Exception as e:
            st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            st.info("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬æˆ–ä½¿ç”¨ç¤ºä¾‹æ•°æ®")

with tab3:
    st.markdown('<h2 class="sub-header">æ¨¡å‹æ¨ç†</h2>', unsafe_allow_html=True)
    
    # æ¨¡å‹åŠ è½½çŠ¶æ€
    model_loaded = False
    model = None
    
    # åŠ è½½æ¨¡å‹æŒ‰é’®
    if st.button("ğŸ¤– åŠ è½½æ¨¡å‹", type="primary"):
        try:
            with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
                # å¯¼å…¥æ¨¡å‹
                from models.models import AGCNrec
                from utils.data_utils import load_data
                
                # åŠ è½½æ•°æ®
                rating, features_item, features_user, support_user, support_item, negative = load_data(
                    user=['uku'],
                    item=['kuk'],
                    data_dir=data_dir
                )
                
                # åˆ›å»ºplaceholders
                placeholders = {
                    'rating': rating,
                    'features_user': features_user,
                    'features_item': features_item,
                    'negative': negative
                }
                
                # åˆ›å»ºæ¨¡å‹
                model = AGCNrec(
                    placeholders=placeholders,
                    input_dim_user=features_user.shape[1],
                    input_dim_item=features_item.shape[1],
                    user_dim=rating.shape[0],
                    item_dim=rating.shape[1],
                    learning_rate=0.001
                )
                
                # åŠ è½½æƒé‡
                if os.path.exists(model_path):
                    model.load(model_path)
                    st.success("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
                    model_loaded = True
                    
                    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                    with st.expander("ğŸ“‹ æ¨¡å‹ä¿¡æ¯"):
                        model_summary = model.summary()
                        st.json(model_summary)
                else:
                    st.warning("âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
                    model_loaded = True
                
        except Exception as e:
            st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    if model_loaded and model is not None:
        # ç”¨æˆ·é€‰æ‹©
        st.markdown("### é€‰æ‹©ç”¨æˆ·è¿›è¡Œæ¨è")
        
        col_user1, col_user2 = st.columns(2)
        
        with col_user1:
            max_user_id = model.user_dim - 1 if hasattr(model, 'user_dim') else 100
            user_id = st.number_input(
                "ç”¨æˆ·ID", 
                min_value=0, 
                max_value=max(0, max_user_id), 
                value=0,
                help=f"é€‰æ‹©ç”¨æˆ·ID (0-{max_user_id})"
            )
        
        with col_user2:
            top_k = st.slider(
                "æ¨èæ•°é‡", 
                min_value=1, 
                max_value=20, 
                value=10,
                help="é€‰æ‹©è¦ç”Ÿæˆçš„æ¨èæ•°é‡"
            )
        
        # ç”Ÿæˆæ¨èæŒ‰é’®
        if st.button("ğŸ¯ ç”Ÿæˆæ¨è", type="primary"):
            try:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ¨è..."):
                    # ç¡®ä¿æœ‰æ•°æ®
                    from utils.data_utils import load_data
                    rating, features_item, features_user, support_user, support_item, negative = load_data(
                        user=['uku'],
                        item=['kuk'],
                        data_dir=data_dir
                    )
                    
                    # è®¾ç½®è®¾å¤‡
                    device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
                    model = model.to(device)
                    
                    # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                    features_user = features_user.to(device)
                    features_item = features_item.to(device)
                    support_user = [sup.to(device) for sup in support_user]
                    support_item = [sup.to(device) for sup in support_item]
                    
                    # å‰å‘ä¼ æ’­
                    with torch.no_grad():
                        model.eval()
                        rate_matrix = model.forward(
                            features_user, features_item,
                            support_user, support_item
                        )
                        
                        # è·å–ç”¨æˆ·çš„è¯„åˆ†
                        user_ratings = rate_matrix[user_id, :]
                        top_scores, top_indices = torch.topk(user_ratings, k=min(top_k, len(user_ratings)))
                        
                        # æ˜¾ç¤ºæ¨èç»“æœ
                        st.markdown(f"### ç”¨æˆ· {user_id} çš„Top-{top_k}æ¨è")
                        
                        # åˆ›å»ºç»“æœè¡¨æ ¼
                        results = []
                        for i, (score, idx) in enumerate(zip(top_scores, top_indices)):
                            results.append({
                                "æ’å": i + 1,
                                "ç‰©å“ID": idx.item(),
                                "é¢„æµ‹è¯„åˆ†": f"{score.item():.4f}",
                                "æ˜Ÿçº§": "â­" * min(5, int(score.item() / 1.0 + 0.5))
                            })
                        
                        results_df = pd.DataFrame(results)
                        st.dataframe(results_df, use_container_width=True)
                        
                        # å¯è§†åŒ–
                        col_viz1, col_viz2 = st.columns(2)
                        
                        with col_viz1:
                            # è¯„åˆ†æŸ±çŠ¶å›¾
                            fig1, ax1 = plt.subplots(figsize=(8, 4))
                            ax1.bar(range(len(top_scores)), top_scores.cpu().numpy(), color='skyblue')
                            ax1.set_xlabel("æ¨èæ’å")
                            ax1.set_ylabel("é¢„æµ‹è¯„åˆ†")
                            ax1.set_title(f"ç”¨æˆ· {user_id} çš„Top-{top_k}æ¨èè¯„åˆ†")
                            ax1.set_xticks(range(len(top_scores)))
                            ax1.set_xticklabels([str(i+1) for i in range(len(top_scores))])
                            st.pyplot(fig1)
                        
                        with col_viz2:
                            # è¯„åˆ†åˆ†å¸ƒ
                            fig2, ax2 = plt.subplots(figsize=(8, 4))
                            all_scores = user_ratings.cpu().numpy()
                            ax2.hist(all_scores, bins=20, alpha=0.7, color='lightgreen')
                            ax2.axvline(x=top_scores[-1].item(), color='red', linestyle='--', label='Top-Ké˜ˆå€¼')
                            ax2.set_xlabel("é¢„æµ‹è¯„åˆ†")
                            ax2.set_ylabel("ç‰©å“æ•°é‡")
                            ax2.set_title(f"ç”¨æˆ· {user_id} çš„æ‰€æœ‰ç‰©å“è¯„åˆ†åˆ†å¸ƒ")
                            ax2.legend()
                            st.pyplot(fig2)
                        
                        # æ¨èè§£é‡Šï¼ˆå¯é€‰ï¼‰
                        with st.expander("ğŸ” æ¨èè§£é‡Š"):
                            st.markdown(f"""
                            ### æ¨èç»“æœåˆ†æ
                            
                            - **ç”¨æˆ·ID**: {user_id}
                            - **æ¨èæ•°é‡**: {top_k}
                            - **æœ€é«˜è¯„åˆ†**: {top_scores[0].item():.4f}
                            - **å¹³å‡è¯„åˆ†**: {top_scores.mean().item():.4f}
                            - **è¯„åˆ†èŒƒå›´**: {top_scores[-1].item():.4f} - {top_scores[0].item():.4f}
                            
                            ### æ¨èè´¨é‡
                            
                            æ ¹æ®é¢„æµ‹è¯„åˆ†ï¼Œè¿™äº›ç‰©å“ä¸ç”¨æˆ·çš„å…´è¶£åŒ¹é…åº¦è¾ƒé«˜ã€‚
                            é«˜è¯„åˆ†çš„ç‰©å“è¡¨æ˜æ¨¡å‹è®¤ä¸ºè¿™äº›å†…å®¹æœ€ç¬¦åˆç”¨æˆ·çš„å­¦ä¹ éœ€æ±‚ã€‚
                            """)
                            
            except Exception as e:
                st.error(f"âŒ æ¨èç”Ÿæˆå¤±è´¥: {e}")

with tab4:
    st.markdown('<h2 class="sub-header">æ€§èƒ½è¯„ä¼°</h2>', unsafe_allow_html=True)
    
    # è¯„ä¼°é€‰é¡¹
    col_eval1, col_eval2 = st.columns(2)
    
    with col_eval1:
        eval_model_path = st.selectbox(
            "é€‰æ‹©è¯„ä¼°æ¨¡å‹",
            options=["./saved_models/best_model.pth", "./saved_models/final_model.pth", "å½“å‰åŠ è½½æ¨¡å‹"],
            index=0
        )
    
    with col_eval2:
        run_eval_btn = st.button("ğŸ“Š è¿è¡Œè¯„ä¼°", type="primary")
    
    if run_eval_btn:
        try:
            with st.spinner("æ­£åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½..."):
                # å¯¼å…¥å¿…è¦çš„æ¨¡å—
                from models.models import AGCNrec
                from utils.data_utils import load_data
                from utils.metrics import print_metrics
                
                # åŠ è½½æ•°æ®
                rating, features_item, features_user, support_user, support_item, negative = load_data(
                    user=['uku'],
                    item=['kuk'],
                    data_dir=data_dir
                )
                
                # åˆ›å»ºplaceholders
                placeholders = {
                    'rating': rating,
                    'features_user': features_user,
                    'features_item': features_item,
                    'negative': negative
                }
                
                # åˆ›å»ºæ¨¡å‹
                model = AGCNrec(
                    placeholders=placeholders,
                    input_dim_user=features_user.shape[1],
                    input_dim_item=features_item.shape[1],
                    user_dim=rating.shape[0],
                    item_dim=rating.shape[1],
                    learning_rate=0.001
                )
                
                # åŠ è½½æŒ‡å®šæ¨¡å‹
                if eval_model_path != "å½“å‰åŠ è½½æ¨¡å‹":
                    if os.path.exists(eval_model_path):
                        model.load(eval_model_path)
                        st.success(f"âœ… åŠ è½½æ¨¡å‹: {eval_model_path}")
                    else:
                        st.warning(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {eval_model_path}")
                        st.info("ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹è¿›è¡Œè¯„ä¼°")
                
                # è®¾ç½®è®¾å¤‡
                device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')
                model = model.to(device)
                
                # ç§»åŠ¨æ•°æ®
                features_user = features_user.to(device)
                features_item = features_item.to(device)
                rating = rating.to(device)
                negative = negative.to(device)
                support_user = [sup.to(device) for sup in support_user]
                support_item = [sup.to(device) for sup in support_item]
                
                # å‡†å¤‡æ‰¹å¤„ç†æ•°æ®
                batch_data = {
                    'features_user': features_user,
                    'features_item': features_item,
                    'rating': rating,
                    'supports_user': support_user,
                    'supports_item': support_item,
                    'negative': negative
                }
                
                # è¯„ä¼°
                with torch.no_grad():
                    metrics = model.evaluate(batch_data)
                
                # æ˜¾ç¤ºç»“æœ
                st.success("âœ… è¯„ä¼°å®Œæˆ!")
                
                # åˆ›å»ºæŒ‡æ ‡å¡ç‰‡
                st.markdown("### è¯„ä¼°ç»“æœ")
                
                # æŒ‰Kå€¼åˆ†ç»„æ˜¾ç¤º
                hr_metrics = {k: v for k, v in metrics.items() if k.startswith('hr@') and int(k.split('@')[1]) in k_values}
                ndcg_metrics = {k: v for k, v in metrics.items() if k.startswith('ndcg@') and int(k.split('@')[1]) in k_values}
                
                # HRæŒ‡æ ‡
                st.markdown("#### Hit Rate (HR)")
                cols_hr = st.columns(len(hr_metrics))
                for idx, (k, v) in enumerate(sorted(hr_metrics.items(), key=lambda x: int(x[0].split('@')[1]))):
                    with cols_hr[idx]:
                        st.metric(f"HR@{k.split('@')[1]}", f"{v:.4f}")
                
                # NDCGæŒ‡æ ‡
                st.markdown("#### Normalized DCG")
                cols_ndcg = st.columns(len(ndcg_metrics))
                for idx, (k, v) in enumerate(sorted(ndcg_metrics.items(), key=lambda x: int(x[0].split('@')[1]))):
                    with cols_ndcg[idx]:
                        st.metric(f"NDCG@{k.split('@')[1]}", f"{v:.4f}")
                
                # å…¶ä»–æŒ‡æ ‡
                st.markdown("#### å…¶ä»–æŒ‡æ ‡")
                other_metrics = {k: v for k, v in metrics.items() if not k.startswith('hr@') and not k.startswith('ndcg@')}
                cols_other = st.columns(len(other_metrics))
                for idx, (k, v) in enumerate(other_metrics.items()):
                    with cols_other[idx]:
                        st.metric(k.upper(), f"{v:.4f}")
                
                # å¯è§†åŒ–
                st.markdown("### æŒ‡æ ‡å¯è§†åŒ–")
                
                fig, axes = plt.subplots(1, 2, figsize=(12, 4))
                
                # HR@Kæ›²çº¿
                hr_values = [metrics.get(f'hr@{k}', 0) for k in sorted(k_values)]
                axes[0].plot(sorted(k_values), hr_values, marker='o', linewidth=2, color='blue')
                axes[0].set_xlabel('K')
                axes[0].set_ylabel('Hit Rate')
                axes[0].set_title('HR@K æ›²çº¿')
                axes[0].grid(True, alpha=0.3)
                
                # NDCG@Kæ›²çº¿
                ndcg_values = [metrics.get(f'ndcg@{k}', 0) for k in sorted([k for k in k_values if k in [5, 10, 20]])]
                ndcg_k_values = [k for k in k_values if k in [5, 10, 20]]
                if ndcg_values:
                    axes[1].plot(ndcg_k_values, ndcg_values, marker='s', linewidth=2, color='green')
                    axes[1].set_xlabel('K')
                    axes[1].set_ylabel('NDCG')
                    axes[1].set_title('NDCG@K æ›²çº¿')
                    axes[1].grid(True, alpha=0.3)
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # è¯¦ç»†æŒ‡æ ‡è¡¨æ ¼
                st.markdown("### è¯¦ç»†æŒ‡æ ‡")
                
                metrics_df = pd.DataFrame([
                    {"æŒ‡æ ‡": k, "å€¼": f"{v:.4f}"}
                    for k, v in metrics.items()
                ])
                
                st.dataframe(metrics_df, use_container_width=True)
                
                # è¯„ä¼°æ€»ç»“
                st.markdown("### è¯„ä¼°æ€»ç»“")
                
                best_hr = max([v for k, v in metrics.items() if k.startswith('hr@')])
                best_hr_k = [k for k, v in metrics.items() if k.startswith('hr@') and v == best_hr][0]
                
                col_sum1, col_sum2 = st.columns(2)
                
                with col_sum1:
                    st.info(f"**æœ€ä½³å‘½ä¸­ç‡**: {best_hr:.4f} ({best_hr_k})")
                    st.info(f"**å¹³å‡å€’æ•°æ’å**: {metrics.get('mrr', 0):.4f}")
                
                with col_sum2:
                    st.info(f"**æ›²çº¿ä¸‹é¢ç§¯**: {metrics.get('auc', 0):.4f}")
                    st.info(f"**è¯„ä¼°ç”¨æˆ·æ•°**: {model.user_dim if hasattr(model, 'user_dim') else 'N/A'}")
                
        except Exception as e:
            st.error(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
            st.info("ğŸ’¡ è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ä¸”æ•°æ®å¯ç”¨")

# é¡µè„š
st.sidebar.markdown("---")
st.sidebar.markdown("""
#### ğŸ“š å…³äºACKRec

- **è®ºæ–‡**: [arXiv:2006.13257](https://arxiv.org/abs/2006.13257)
- **GitHub**: [AI4Edu-Group/ACKRec](https://github.com/AI4Edu-Group/ACKRec)
- **ç‰ˆæœ¬**: 1.0.0

#### ğŸ“§ æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤GitHub Issueæˆ–è”ç³»æˆ‘ä»¬ã€‚
""")

# è¿è¡ŒçŠ¶æ€
if st.sidebar.button("ğŸ”„ æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"):
    import subprocess
    result = subprocess.run([sys.executable, "--version"], capture_output=True, text=True)
    st.sidebar.code(f"Python: {result.stdout.strip()}")
    st.sidebar.code(f"PyTorch: {torch.__version__}")
    st.sidebar.code(f"CUDA: {'å¯ç”¨' if torch.cuda.is_available() else 'ä¸å¯ç”¨'}")

# æ·»åŠ åˆ·æ–°æŒ‰é’®
if st.sidebar.button("ğŸ”„ åˆ·æ–°é¡µé¢"):
    st.rerun()