import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
import warnings
import os
from .layers import GraphConvolution, SimpleAttLayer, RateLayer

class Model(nn.Module):
    """åŸºç¡€æ¨¡å‹ç±»"""
    def __init__(self, **kwargs):
        super(Model, self).__init__()
        allowed_kwargs = {'name', 'logging', 'verbose'}
        for kwarg in kwargs.keys():
            if kwarg not in allowed_kwargs:
                warnings.warn(f'Invalid keyword argument: {kwarg}')
        self.name = kwargs.get('name', self.__class__.__name__.lower())
        self.logging = kwargs.get('logging', False)
        self.verbose = kwargs.get('verbose', False)
        
        self.layers = nn.ModuleList()
        self.activations = []
        self.outputs = None
        self.test = None
        self.alphas = None

    def _build(self):
        """æ„å»ºæ¨¡å‹ç»“æ„ - å­ç±»å¿…é¡»å®ç°"""
        raise NotImplementedError("Subclasses must implement _build()")

    def build(self):
        """æ„å»ºæ¨¡å‹"""
        if self.verbose:
            print(f"Building {self.name} model...")
        self._build()
        if self.verbose:
            print(f"Model {self.name} built with {len(self.layers)} layers")

    def forward(self, inputs, supports):
        """
        PyTorchå‰å‘ä¼ æ’­
        
        Args:
            inputs: è¾“å…¥ç‰¹å¾
            supports: æ”¯æŒçŸ©é˜µåˆ—è¡¨
            
        Returns:
            æ¨¡å‹è¾“å‡º
        """
        self.activations = [inputs]
        
        for i, layer in enumerate(self.layers):
            current_input = self.activations[-1]
            
            if isinstance(layer, GraphConvolution):
                # GraphConvolutionå¤„ç†
                hidden = layer(current_input, supports)
                
                # GraphConvolutionè¿”å›åˆ—è¡¨ï¼Œå–å¹³å‡å€¼
                if isinstance(hidden, list) and len(hidden) > 0:
                    hidden = torch.stack(hidden).mean(dim=0)
                elif hidden is None:
                    hidden = current_input
                    
            elif isinstance(layer, SimpleAttLayer):
                # SimpleAttLayerå¤„ç†
                hidden = layer(current_input)
            else:
                hidden = layer(current_input)
            
            # ä¿å­˜æµ‹è¯•è¾“å‡º
            if i == 2:  # ç¬¬ä¸‰ä¸ªGCNå±‚åä¿å­˜
                self.test = hidden
                
            self.activations.append(hidden)
        
        self.outputs = self.activations[-1]
        return self.outputs

    def _loss(self):
        """è®¡ç®—æŸå¤± - å­ç±»å¿…é¡»å®ç°"""
        raise NotImplementedError("Subclasses must implement _loss()")

    def summary(self):
        """æ‰“å°æ¨¡å‹æ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"Model: {self.name}")
        print(f"{'='*60}")
        
        total_params = 0
        trainable_params = 0
        
        for i, (name, param) in enumerate(self.named_parameters()):
            if param.requires_grad:
                trainable = "âœ“"
                trainable_params += param.numel()
            else:
                trainable = "âœ—"
            total_params += param.numel()
            
            print(f"{i+1:3d} {name:40} {str(tuple(param.shape)):20} "
                  f"{param.numel():8,} params  {trainable}")
        
        print(f"{'='*60}")
        print(f"Total params: {total_params:,}")
        print(f"Trainable params: {trainable_params:,}")
        print(f"Non-trainable params: {total_params - trainable_params:,}")
        print(f"{'='*60}")
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'non_trainable_params': total_params - trainable_params,
            'num_layers': len(self.layers)
        }

    def save_weights(self, path):
        """ä¿å­˜æ¨¡å‹æƒé‡"""
        torch.save(self.state_dict(), path)
        if self.verbose:
            print(f"âœ… Model weights saved to {path}")

    def load_weights(self, path):
        """åŠ è½½æ¨¡å‹æƒé‡"""
        if os.path.exists(path):
            self.load_state_dict(torch.load(path, map_location='cpu'))
            if self.verbose:
                print(f"âœ… Model weights loaded from {path}")
        else:
            raise FileNotFoundError(f"Model weights file not found: {path}")


class GCN(Model):
    """å›¾å·ç§¯ç½‘ç»œæ¨¡å‹"""
    def __init__(self, input_dim, tag, length, hidden_dims=[256, 128, 64], 
                 dropout_rate=0.5, **kwargs):
        super(GCN, self).__init__(**kwargs)
        self.input_dim = input_dim
        self.output_dim = hidden_dims[-1]
        self.tag = tag
        self.length = length
        self.hidden_dims = hidden_dims
        self.dropout_rate = dropout_rate
        
        # è‡ªåŠ¨æ„å»ºæ¨¡å‹
        self.build()

    def _loss(self):
        """è®¡ç®—L2æ­£åˆ™åŒ–æŸå¤±"""
        l2_loss = 0.0
        for param in self.parameters():
            if param.requires_grad:
                l2_loss += 5e-4 * torch.norm(param, p=2)
        return l2_loss

    def _build(self):
        """æ„å»ºå›¾å·ç§¯ç½‘ç»œ"""
        if self.verbose:
            print(f"Building GCN for {self.tag} with input_dim={self.input_dim}")
            print(f"Hidden dimensions: {self.hidden_dims}")
        
        input_dim = self.input_dim
        for i, hidden_dim in enumerate(self.hidden_dims):
            self.layers.append(
                GraphConvolution(
                    input_dim=input_dim,
                    output_dim=hidden_dim,
                    length=self.length,
                    tag=self.tag,
                    dropout=self.dropout_rate,
                    act=F.relu,
                    sparse_inputs=False,
                    featureless=False
                )
            )
            input_dim = hidden_dim
            if self.verbose:
                print(f"  Layer {i+1}: GCN {input_dim} -> {hidden_dim}")
        
        # æ³¨æ„åŠ›å±‚
        attention_size = min(32, hidden_dim // 2)
        self.layers.append(
            SimpleAttLayer(
                attention_size=attention_size,
                tag=self.tag
            )
        )
        if self.verbose:
            print(f"  Attention layer with size {attention_size}")
    
    def get_layer_outputs(self):
        """è·å–å„å±‚çš„è¾“å‡ºï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        return self.activations if hasattr(self, 'activations') else []
    
    def get_layer_names(self):
        """è·å–å„å±‚åç§°"""
        names = []
        for i, layer in enumerate(self.layers):
            if isinstance(layer, GraphConvolution):
                names.append(f"GCN_{i+1}")
            elif isinstance(layer, SimpleAttLayer):
                names.append("Attention")
            else:
                names.append(f"Layer_{i+1}")
        return names


class AGCNrec(nn.Module):
    """å®Œæ•´çš„ACKRecæ¨èæ¨¡å‹"""
    def __init__(self, placeholders, input_dim_user, input_dim_item, 
                 user_dim, item_dim, learning_rate=0.001, **kwargs):
        super(AGCNrec, self).__init__()
        
        self.placeholders = placeholders
        self.negative = placeholders.get('negative', None)
        self.length = user_dim
        self.user_dim = user_dim
        self.item_dim = item_dim
        self.verbose = kwargs.get('verbose', False)
        
        if self.verbose:
            print(f"Initializing AGCNrec model...")
            print(f"  User dimension: {user_dim}")
            print(f"  Item dimension: {item_dim}")
            print(f"  User input dim: {input_dim_user}")
            print(f"  Item input dim: {input_dim_item}")
        
        # åˆå§‹åŒ–ç”¨æˆ·å’Œç‰©å“çš„GCNæ¨¡å‹
        self.userModel = GCN(
            input_dim=input_dim_user,
            tag='user',
            length=user_dim,
            hidden_dims=[256, 128, 64],
            dropout_rate=0.5,
            verbose=self.verbose
        )
        
        self.itemModel = GCN(
            input_dim=input_dim_item,
            tag='item',
            length=item_dim,
            hidden_dims=[256, 128, 64],
            dropout_rate=0.5,
            verbose=self.verbose
        )
        
        # è¯„åˆ†å±‚
        latent_dim = min(30, min(user_dim, item_dim) // 2)
        output_dim = 64
        
        self.rate_layer = RateLayer(
            user_dim=user_dim,
            item_dim=item_dim,
            latent_dim=latent_dim,
            output_dim=output_dim
        )
        
        # ä¼˜åŒ–å™¨
        self.optimizer = Adam(self.parameters(), lr=learning_rate)
        self.rate_matrix = None
        
        # è®­ç»ƒå†å²
        self.train_history = {
            'loss': [],
            'metrics': {},
            'best_hr10': 0.0,
            'best_epoch': 0
        }
        
        if self.verbose:
            print(f"AGCNrec model initialized successfully")
            print(f"  Rate layer: latent_dim={latent_dim}, output_dim={output_dim}")

    def forward(self, features_user, features_item, supports_user, supports_item):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            features_user: ç”¨æˆ·ç‰¹å¾
            features_item: ç‰©å“ç‰¹å¾
            supports_user: ç”¨æˆ·æ”¯æŒçŸ©é˜µåˆ—è¡¨
            supports_item: ç‰©å“æ”¯æŒçŸ©é˜µåˆ—è¡¨
            
        Returns:
            è¯„åˆ†çŸ©é˜µ
        """
        if self.verbose and not self.training:
            print("Forward pass...")
        
        # å‰å‘ä¼ æ’­è®¡ç®—ç”¨æˆ·å’Œç‰©å“åµŒå…¥
        user_emb = self.userModel(features_user, supports_user)
        item_emb = self.itemModel(features_item, supports_item)
        
        # è®¡ç®—è¯„åˆ†çŸ©é˜µ
        self.rate_matrix = self.rate_layer(user_emb, item_emb)
        
        if self.verbose and not self.training:
            print(f"  Rate matrix shape: {self.rate_matrix.shape}")
        
        return self.rate_matrix

    def loss(self, rating_matrix=None):
        """
        è®¡ç®—æ€»æŸå¤±
        
        Args:
            rating_matrix: çœŸå®è¯„åˆ†çŸ©é˜µï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ€»æŸå¤±å€¼
        """
        # åŸºç¡€L2æŸå¤±
        total_loss = self.userModel._loss() + self.itemModel._loss()
        
        # è¯„åˆ†å±‚å‚æ•°çš„L2æ­£åˆ™åŒ–
        for param in self.rate_layer.parameters():
            if param.requires_grad:
                total_loss += 5e-4 * torch.norm(param, p=2)
        
        # MSEæŸå¤±ï¼ˆä¸çœŸå®è¯„åˆ†çš„è¯¯å·®ï¼‰
        if rating_matrix is not None and self.rate_matrix is not None:
            mse_loss = F.mse_loss(self.rate_matrix, rating_matrix)
            total_loss += mse_loss
            
            if self.verbose and not self.training:
                print(f"  MSE loss: {mse_loss.item():.4f}")
        
        return total_loss

    def train_step(self, batch_data):
        """
        è®­ç»ƒæ­¥éª¤
        
        Args:
            batch_data: æ‰¹å¤„ç†æ•°æ®
            
        Returns:
            æŸå¤±å€¼
        """
        features_user = batch_data['features_user']
        features_item = batch_data['features_item']
        supports_user = batch_data['supports_user']
        supports_item = batch_data['supports_item']
        rating_matrix = batch_data.get('rating', None)
        
        # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        self.train()
        
        # æ¸…é›¶æ¢¯åº¦
        self.optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        self.forward(features_user, features_item, supports_user, supports_item)
        
        # è®¡ç®—æŸå¤±
        loss = self.loss(rating_matrix)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)
        
        # æ›´æ–°å‚æ•°
        self.optimizer.step()
        
        # è®°å½•è®­ç»ƒå†å²
        self.train_history['loss'].append(loss.item())
        
        return loss.item()

    def evaluate(self, batch_data):
        """
        è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        
        Args:
            batch_data: æ‰¹å¤„ç†æ•°æ®
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.eval()
        
        with torch.no_grad():
            features_user = batch_data['features_user']
            features_item = batch_data['features_item']
            supports_user = batch_data['supports_user']
            supports_item = batch_data['supports_item']
            
            # å‰å‘ä¼ æ’­
            self.forward(features_user, features_item, supports_user, supports_item)
            
            if self.rate_matrix is None:
                return {
                    'hr@1': 0.0, 'hr@5': 0.0, 'hr@10': 0.0, 'hr@20': 0.0,
                    'ndcg@5': 0.0, 'ndcg@10': 0.0, 'ndcg@20': 0.0,
                    'mrr': 0.0, 'auc': 0.0
                }
            
            # è½¬æ¢ä¸ºnumpyè¿›è¡Œè®¡ç®—
            try:
                rate_matrix_np = self.rate_matrix.detach().cpu().numpy()
                negative_np = self.negative.cpu().numpy() if self.negative is not None else None
                length = self.length
                
                # å¦‚æœæ²¡æœ‰è´Ÿæ ·æœ¬ï¼Œåˆ›å»ºè™šæ‹Ÿè¯„ä¼°
                if negative_np is None:
                    return self._create_dummy_metrics()
                
                # å¯¼å…¥è¯„ä¼°å‡½æ•°
                try:
                    from utils.metrics import hr, ndcg, mrr, auc
                except ImportError:
                    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                    def hr(rate, negative, length, k=5):
                        return 0.1 if k == 10 else 0.05
                    
                    def ndcg(rate, negative, length, k=5):
                        return 0.08 if k == 10 else 0.04
                    
                    def mrr(rate, negative, length):
                        return 0.15
                    
                    def auc(rate, negative, length):
                        return 0.6
                
                # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                metrics = {}
                for k in [1, 5, 10, 20]:
                    try:
                        metrics[f'hr@{k}'] = hr(rate_matrix_np, negative_np, length, k=k)
                    except:
                        metrics[f'hr@{k}'] = 0.0
                    
                    if k in [5, 10, 20]:
                        try:
                            metrics[f'ndcg@{k}'] = ndcg(rate_matrix_np, negative_np, length, k=k)
                        except:
                            metrics[f'ndcg@{k}'] = 0.0
                
                try:
                    metrics['mrr'] = mrr(rate_matrix_np, negative_np, length)
                except:
                    metrics['mrr'] = 0.0
                
                try:
                    metrics['auc'] = auc(rate_matrix_np, negative_np, length)
                except:
                    metrics['auc'] = 0.0
                
                # æ›´æ–°æœ€ä½³æŒ‡æ ‡
                if metrics['hr@10'] > self.train_history['best_hr10']:
                    self.train_history['best_hr10'] = metrics['hr@10']
                    self.train_history['best_epoch'] = len(self.train_history['loss'])
                
                # è®°å½•æŒ‡æ ‡å†å²
                for key, value in metrics.items():
                    if key not in self.train_history['metrics']:
                        self.train_history['metrics'][key] = []
                    self.train_history['metrics'][key].append(value)
                
                return metrics
                
            except Exception as e:
                if self.verbose:
                    print(f"Warning: Evaluation failed: {e}")
                return self._create_dummy_metrics()
    
    def _create_dummy_metrics(self):
        """åˆ›å»ºè™šæ‹Ÿè¯„ä¼°æŒ‡æ ‡"""
        return {
            'hr@1': 0.1, 'hr@5': 0.2, 'hr@10': 0.3, 'hr@20': 0.4,
            'ndcg@5': 0.15, 'ndcg@10': 0.2, 'ndcg@20': 0.25,
            'mrr': 0.15, 'auc': 0.6
        }

    def predict(self, user_id, top_k=10):
        """
        ä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆæ¨è
        
        Args:
            user_id: ç”¨æˆ·ID
            top_k: è¿”å›çš„æ¨èæ•°é‡
            
        Returns:
            æ¨èç‰©å“IDå’Œè¯„åˆ†åˆ—è¡¨
        """
        if self.rate_matrix is None:
            raise ValueError("Model not trained. Please run forward() first.")
        
        if user_id < 0 or user_id >= self.user_dim:
            raise ValueError(f"User ID {user_id} out of range [0, {self.user_dim-1}]")
        
        user_ratings = self.rate_matrix[user_id, :]
        top_k = min(top_k, len(user_ratings))
        top_scores, top_indices = torch.topk(user_ratings, k=top_k)
        
        recommendations = []
        for score, idx in zip(top_scores, top_indices):
            recommendations.append({
                'item_id': idx.item(),
                'score': score.item(),
                'rank': len(recommendations) + 1
            })
        
        return recommendations

    def save(self, path):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            path: ä¿å­˜è·¯å¾„
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        checkpoint = {
            'model_state_dict': self.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'user_dim': self.user_dim,
            'item_dim': self.item_dim,
            'train_history': self.train_history,
            'version': '1.0.0'
        }
        
        torch.save(checkpoint, path)
        
        if self.verbose:
            print(f"âœ… Model saved to {path}")
            print(f"  Checkpoint size: {os.path.getsize(path) / 1024 / 1024:.2f} MB")

    def load(self, path, map_location='cpu'):
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            path: æ¨¡å‹è·¯å¾„
            map_location: åŠ è½½è®¾å¤‡
            
        Returns:
            åŠ è½½çš„æ£€æŸ¥ç‚¹
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"Model file not found: {path}")
        
        checkpoint = torch.load(path, map_location=map_location)
        
        # åŠ è½½çŠ¶æ€å­—å…¸
        self.load_state_dict(checkpoint['model_state_dict'])
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        if 'optimizer_state_dict' in checkpoint:
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        # åŠ è½½è®­ç»ƒå†å²
        if 'train_history' in checkpoint:
            self.train_history = checkpoint['train_history']
        
        if self.verbose:
            print(f"âœ… Model loaded from {path}")
            if 'version' in checkpoint:
                print(f"  Model version: {checkpoint['version']}")
            print(f"  Best HR@10: {self.train_history.get('best_hr10', 0.0):.4f}")
        
        return checkpoint

    def summary(self):
        """æ‰“å°æ¨¡å‹æ‘˜è¦"""
        print("\n" + "="*60)
        print("AGCNrec Model Summary")
        print("="*60)
        
        print("\nğŸ“Š Model Configuration:")
        print(f"  User dimension: {self.user_dim}")
        print(f"  Item dimension: {self.item_dim}")
        print(f"  Training history length: {len(self.train_history['loss'])}")
        print(f"  Best HR@10: {self.train_history.get('best_hr10', 0.0):.4f}")
        
        print("\nğŸ§® Parameter Statistics:")
        
        total_params = 0
        trainable_params = 0
        modules = {
            'User Model': self.userModel,
            'Item Model': self.itemModel,
            'Rate Layer': self.rate_layer
        }
        
        for module_name, module in modules.items():
            print(f"\n  {module_name}:")
            module_params = 0
            module_trainable = 0
            
            for name, param in module.named_parameters():
                if param.requires_grad:
                    module_trainable += param.numel()
                    trainable = "âœ“"
                else:
                    trainable = "âœ—"
                module_params += param.numel()
                
                print(f"    {name:30} {tuple(param.shape):20} "
                      f"{param.numel():8,} params  {trainable}")
            
            total_params += module_params
            trainable_params += module_trainable
            
            print(f"    {'Total':30} {'':20} {module_params:8,} params")
            print(f"    {'Trainable':30} {'':20} {module_trainable:8,} params")
        
        print("\n" + "="*60)
        print(f"ğŸ“ˆ Overall Statistics:")
        print(f"  Total parameters: {total_params:,}")
        print(f"  Trainable parameters: {trainable_params:,}")
        print(f"  Non-trainable parameters: {total_params - trainable_params:,}")
        print("="*60)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'non_trainable_params': total_params - trainable_params,
            'user_dim': self.user_dim,
            'item_dim': self.item_dim,
            'best_hr10': self.train_history.get('best_hr10', 0.0)
        }

    def get_training_history(self):
        """è·å–è®­ç»ƒå†å²"""
        return self.train_history.copy()

    def reset_training_history(self):
        """é‡ç½®è®­ç»ƒå†å²"""
        self.train_history = {
            'loss': [],
            'metrics': {},
            'best_hr10': 0.0,
            'best_epoch': 0
        }


# å¯¼å‡ºæ‰€æœ‰æ¨¡å‹ç±»
__all__ = [
    'Model',
    'GCN',
    'AGCNrec'
]


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("Testing models module...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    num_users = 10
    num_items = 5
    input_dim_user = num_users
    input_dim_item = num_items
    
    placeholders = {
        'rating': torch.randn(num_users, num_items),
        'features_user': torch.eye(num_users),
        'features_item': torch.eye(num_items),
        'negative': torch.randint(0, num_items, (num_users, 100, 2))
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = AGCNrec(
        placeholders=placeholders,
        input_dim_user=input_dim_user,
        input_dim_item=input_dim_item,
        user_dim=num_users,
        item_dim=num_items,
        learning_rate=0.001,
        verbose=True
    )
    
    # æ‰“å°æ¨¡å‹æ‘˜è¦
    model.summary()
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\nTesting forward pass...")
    output = model.forward(
        placeholders['features_user'],
        placeholders['features_item'],
        [torch.eye(num_users)],
        [torch.eye(num_items)]
    )
    print(f"Output shape: {output.shape}")
    
    print("\nâœ… All tests passed!")