import numpy as np
import pickle as pkl
import random
import scipy.sparse as sp
import torch
import os
import warnings

def load_data(user=['uku'], item=['kuk'], data_dir='./data'):
    """
    åŠ è½½æ•°æ®å¹¶é¢„å¤„ç†
    
    Args:
        user: ç”¨æˆ·æ”¯æŒçŸ©é˜µç±»å‹åˆ—è¡¨
        item: ç‰©å“æ”¯æŒçŸ©é˜µç±»å‹åˆ—è¡¨
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        
    Returns:
        rating: è¯„åˆ†çŸ©é˜µ
        features_item: ç‰©å“ç‰¹å¾
        features_user: ç”¨æˆ·ç‰¹å¾
        support_user: ç”¨æˆ·æ”¯æŒçŸ©é˜µåˆ—è¡¨
        support_item: ç‰©å“æ”¯æŒçŸ©é˜µåˆ—è¡¨
        negative: è´Ÿæ ·æœ¬
    """
    support_user = []
    support_item = []
    
    # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    try:
        # rating matrix
        rating_path = os.path.join(data_dir, 'rate_matrix.p')
        if not os.path.exists(rating_path):
            # å°è¯•åŠ è½½æ ·æœ¬æ•°æ®
            rating_path = os.path.join(data_dir, 'sample_rate_matrix.p')
            if not os.path.exists(rating_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¯„åˆ†çŸ©é˜µæ–‡ä»¶: {rating_path}")
        
        with open(rating_path, 'rb') as source:
            rating = pkl.load(source)
            if hasattr(rating, 'todense'):
                rating = rating.todense()
            rating = np.array(rating, dtype=np.float32)
        
        # concept w2v features
        w2v_path = os.path.join(data_dir, 'concept_embedding.p')
        if os.path.exists(w2v_path):
            with open(w2v_path, 'rb') as source:
                concept_w2v = np.array(pkl.load(source))
        else:
            # ä½¿ç”¨éšæœºç‰¹å¾
            concept_w2v = np.random.randn(rating.shape[1], 50).astype(np.float32)
            warnings.warn(f"æ‰¾ä¸åˆ°è¯å‘é‡ç‰¹å¾æ–‡ä»¶: {w2v_path}ï¼Œä½¿ç”¨éšæœºç‰¹å¾ä»£æ›¿")
        
        # concept bow features
        bow_path = os.path.join(data_dir, 'concept_feature_bow.p')
        if os.path.exists(bow_path):
            with open(bow_path, 'rb') as source:
                concept_bow = pkl.load(source)
                if hasattr(concept_bow, 'todense'):
                    concept_bow = concept_bow.todense()
        else:
            # ä½¿ç”¨éšæœºç‰¹å¾
            concept_bow = np.random.randn(rating.shape[1], 100).astype(np.float32)
            warnings.warn(f"æ‰¾ä¸åˆ°BOWç‰¹å¾æ–‡ä»¶: {bow_path}ï¼Œä½¿ç”¨éšæœºç‰¹å¾ä»£æ›¿")
        
        # åˆå¹¶ç‰¹å¾
        if concept_w2v.shape[0] == concept_bow.shape[0]:
            concept = np.hstack((concept_w2v, concept_bow))
        else:
            # å¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œåªä½¿ç”¨å…¶ä¸­ä¸€ä¸ª
            if concept_w2v.shape[0] == rating.shape[1]:
                concept = concept_w2v
            else:
                concept = concept_bow
            warnings.warn("ç‰¹å¾ç»´åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨å•ä¸ªç‰¹å¾é›†")
        
        features_item = preprocess_features(concept.astype(np.float32))
        
        # user features
        uc_path = os.path.join(data_dir, 'UC.p')
        if os.path.exists(uc_path):
            with open(uc_path, 'rb') as source:
                features = pkl.load(source)
                if hasattr(features, 'todense'):
                    features = features.todense()
                features_user = preprocess_features(features.astype(np.float32))
        else:
            # ä½¿ç”¨å•ä½çŸ©é˜µä½œä¸ºç”¨æˆ·ç‰¹å¾
            features_user = np.eye(rating.shape[0], dtype=np.float32)
            warnings.warn(f"æ‰¾ä¸åˆ°ç”¨æˆ·ç‰¹å¾æ–‡ä»¶: {uc_path}ï¼Œä½¿ç”¨å•ä½çŸ©é˜µä»£æ›¿")
        
        # uku/kuk adjacency matrix
        if 'uku' in user or 'kuk' in item:
            adj_path = os.path.join(data_dir, 'adjacency_matrix.p')
            if os.path.exists(adj_path):
                with open(adj_path, 'rb') as source:
                    uk = pkl.load(source)
                    if hasattr(uk, 'todense'):
                        uk = uk.todense()
                
                if 'uku' in user:
                    uk_user = uk.dot(uk.T) + np.eye(uk.shape[0])
                    uku = preprocess_adj(uk_user)
                    support_user.append(uku)
                
                if 'kuk' in item:
                    ku_item = uk.T.dot(uk) + np.eye(uk.T.shape[0])
                    kuk = preprocess_adj(ku_item)
                    support_item.append(kuk)
            else:
                warnings.warn(f"æ‰¾ä¸åˆ°é‚»æ¥çŸ©é˜µæ–‡ä»¶: {adj_path}")
        
        # ucu matrix
        if 'ucu' in user:
            uc_path = os.path.join(data_dir, 'UC.p')
            if os.path.exists(uc_path):
                with open(uc_path, 'rb') as source:
                    uc = pkl.load(source)
                    if hasattr(uc, 'todense'):
                        uc = uc.todense()
                uc = uc.dot(uc.T) + np.eye(uc.shape[0])
                ucu = preprocess_adj(uc)
                support_user.append(ucu)
        
        # uctcu matrix
        if 'uctcu' in user:
            uct_path = os.path.join(data_dir, 'UCT.p')
            if os.path.exists(uct_path):
                with open(uct_path, 'rb') as source:
                    uct = pkl.load(source)
                    if hasattr(uct, 'todense'):
                        uct = uct.todense()
                uct = uct.dot(uct.T) + np.eye(uct.shape[0])
                uctcu = preprocess_adj(uct)
                support_user.append(uctcu)
            else:
                warnings.warn(f"æ‰¾ä¸åˆ°UCTçŸ©é˜µæ–‡ä»¶: {uct_path}")
        
        # uvu matrix
        if 'uvu' in user:
            uv_path = os.path.join(data_dir, 'UV.p')
            if os.path.exists(uv_path):
                with open(uv_path, 'rb') as source:
                    uv = pkl.load(source)
                    if hasattr(uv, 'todense'):
                        uv = uv.todense()
                uv = uv.dot(uv.T) + np.eye(uv.shape[0])
                uvu = preprocess_adj(uv)
                support_user.append(uvu)
            else:
                warnings.warn(f"æ‰¾ä¸åˆ°UVçŸ©é˜µæ–‡ä»¶: {uv_path}")
        
        # negative sample
        negative_path = os.path.join(data_dir, 'negative.p')
        if os.path.exists(negative_path):
            with open(negative_path, 'rb') as source:
                negative = np.array(pkl.load(source), dtype=np.int32)
        else:
            # ä½¿ç”¨æ ·æœ¬è´Ÿæ ·æœ¬
            negative_path = os.path.join(data_dir, 'sample_negative.p')
            if os.path.exists(negative_path):
                with open(negative_path, 'rb') as source:
                    negative = np.array(pkl.load(source), dtype=np.int32)
            else:
                # åˆ›å»ºè™šæ‹Ÿè´Ÿæ ·æœ¬
                negative = np.zeros((rating.shape[0], 100, 2), dtype=np.int32)
                warnings.warn(f"æ‰¾ä¸åˆ°è´Ÿæ ·æœ¬æ–‡ä»¶ï¼Œä½¿ç”¨è™šæ‹Ÿè´Ÿæ ·æœ¬")
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        rating = torch.FloatTensor(rating)
        features_item = torch.FloatTensor(features_item)
        features_user = torch.FloatTensor(features_user)
        
        # å¤„ç†æ”¯æŒçŸ©é˜µ
        support_user_tensors = []
        for sup in support_user:
            if sup is not None:
                support_user_tensors.append(torch.FloatTensor(sup))
        
        support_item_tensors = []
        for sup in support_item:
            if sup is not None:
                support_item_tensors.append(torch.FloatTensor(sup))
        
        negative = torch.LongTensor(negative)
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"   è¯„åˆ†çŸ©é˜µ: {rating.shape}")
        print(f"   ç”¨æˆ·ç‰¹å¾: {features_user.shape}")
        print(f"   ç‰©å“ç‰¹å¾: {features_item.shape}")
        print(f"   è´Ÿæ ·æœ¬: {negative.shape}")
        print(f"   ç”¨æˆ·æ”¯æŒçŸ©é˜µ: {len(support_user_tensors)} ä¸ª")
        print(f"   ç‰©å“æ”¯æŒçŸ©é˜µ: {len(support_item_tensors)} ä¸ª")
        
        return rating, features_item, features_user, support_user_tensors, support_item_tensors, negative
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise

def load_new_dataset(data_dir='./processed_data'):
    """
    åŠ è½½æ–°æ•°æ®é›†
    
    Args:
        data_dir: å¤„ç†åçš„æ•°æ®ç›®å½•
        
    Returns:
        ä¸load_dataç›¸åŒçš„è¿”å›å€¼
    """
    return load_data(user=['uku'], item=['kuk'], data_dir=data_dir)

def preprocess_features(features):
    """
    ç‰¹å¾å½’ä¸€åŒ–
    
    Args:
        features: è¾“å…¥ç‰¹å¾çŸ©é˜µ
        
    Returns:
        å½’ä¸€åŒ–åçš„ç‰¹å¾
    """
    if isinstance(features, torch.Tensor):
        features = features.numpy()
    
    rowsum = np.array(features.sum(1))
    r_inv = np.power(rowsum, -1).flatten()
    r_inv[np.isinf(r_inv)] = 0.
    r_mat_inv = np.diag(r_inv)
    features = r_mat_inv.dot(features)
    return features

def preprocess_adj(adjacency):
    """
    é‚»æ¥çŸ©é˜µå½’ä¸€åŒ–
    
    Args:
        adjacency: è¾“å…¥é‚»æ¥çŸ©é˜µ
        
    Returns:
        å½’ä¸€åŒ–åçš„é‚»æ¥çŸ©é˜µ
    """
    if isinstance(adjacency, torch.Tensor):
        adjacency = adjacency.numpy()
    
    rowsum = np.array(adjacency.sum(1))
    d_inv_sqrt = np.power(rowsum, -0.5).flatten()
    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.
    d_mat_inv_sqrt = np.diag(d_inv_sqrt)
    return adjacency.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt) * 1e2

def construct_batch_data(features_user, features_item, rating, supports_user, supports_item, negative):
    """
    æ„é€ æ‰¹å¤„ç†æ•°æ®å­—å…¸
    
    Args:
        features_user: ç”¨æˆ·ç‰¹å¾
        features_item: ç‰©å“ç‰¹å¾
        rating: è¯„åˆ†çŸ©é˜µ
        supports_user: ç”¨æˆ·æ”¯æŒçŸ©é˜µ
        supports_item: ç‰©å“æ”¯æŒçŸ©é˜µ
        negative: è´Ÿæ ·æœ¬
        
    Returns:
        æ‰¹å¤„ç†æ•°æ®å­—å…¸
    """
    return {
        'features_user': features_user,
        'features_item': features_item,
        'rating': rating,
        'supports_user': supports_user,
        'supports_item': supports_item,
        'negative': negative
    }

def create_dummy_data(num_users=100, num_items=50):
    """
    åˆ›å»ºè™šæ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
    
    Args:
        num_users: ç”¨æˆ·æ•°é‡
        num_items: ç‰©å“æ•°é‡
        
    Returns:
        è™šæ‹Ÿæ•°æ®
    """
    print(f"åˆ›å»ºè™šæ‹Ÿæ•°æ®: {num_users} ç”¨æˆ·, {num_items} ç‰©å“")
    
    # åˆ›å»ºè¯„åˆ†çŸ©é˜µï¼ˆç¨€ç–ï¼‰
    rating = np.zeros((num_users, num_items), dtype=np.float32)
    for i in range(num_users):
        # æ¯ä¸ªç”¨æˆ·éšæœºäº¤äº’5-10ä¸ªç‰©å“
        num_interactions = np.random.randint(5, 11)
        items = np.random.choice(num_items, num_interactions, replace=False)
        ratings = np.random.uniform(3, 5, num_interactions)
        rating[i, items] = ratings
    
    # åˆ›å»ºç‰¹å¾
    features_user = np.eye(num_users, dtype=np.float32)
    features_item = np.random.randn(num_items, 100).astype(np.float32)
    
    # åˆ›å»ºé‚»æ¥çŸ©é˜µï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
    adjacency = rating > 0
    adjacency = adjacency.astype(np.float32)
    
    # åˆ›å»ºæ”¯æŒçŸ©é˜µ
    uk_user = adjacency.dot(adjacency.T) + np.eye(num_users)
    uku = preprocess_adj(uk_user)
    
    ku_item = adjacency.T.dot(adjacency) + np.eye(num_items)
    kuk = preprocess_adj(ku_item)
    
    # åˆ›å»ºè´Ÿæ ·æœ¬
    negative = np.zeros((num_users, 100, 2), dtype=np.int32)
    for i in range(num_users):
        # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»º99ä¸ªè´Ÿæ ·æœ¬å’Œ1ä¸ªæ­£æ ·æœ¬
        positive_items = np.where(rating[i] > 0)[0]
        if len(positive_items) > 0:
            # é€‰æ‹©ä¸€ä¸ªæ­£æ ·æœ¬
            positive_idx = np.random.choice(positive_items)
            # åˆ›å»º99ä¸ªè´Ÿæ ·æœ¬ï¼ˆç¡®ä¿ä¸æ˜¯æ­£æ ·æœ¬ï¼‰
            all_items = np.arange(num_items)
            negative_items = np.setdiff1d(all_items, positive_items)
            if len(negative_items) >= 99:
                selected_negatives = np.random.choice(negative_items, 99, replace=False)
            else:
                # å¦‚æœè´Ÿæ ·æœ¬ä¸å¤Ÿï¼Œå…è®¸é‡å¤
                selected_negatives = np.random.choice(negative_items, 99, replace=True)
            
            # ç»„åˆï¼šå‰99ä¸ªè´Ÿæ ·æœ¬ï¼Œæœ€åä¸€ä¸ªæ­£æ ·æœ¬
            for j in range(99):
                negative[i, j] = [i, selected_negatives[j]]
            negative[i, 99] = [i, positive_idx]
    
    # è½¬æ¢ä¸ºå¼ é‡
    rating = torch.FloatTensor(rating)
    features_item = torch.FloatTensor(features_item)
    features_user = torch.FloatTensor(features_user)
    support_user = [torch.FloatTensor(uku)]
    support_item = [torch.FloatTensor(kuk)]
    negative = torch.LongTensor(negative)
    
    return rating, features_item, features_user, support_user, support_item, negative

def save_sample_data(data_dir='./data'):
    """
    ä¿å­˜æ ·æœ¬æ•°æ®
    
    Args:
        data_dir: æ•°æ®ç›®å½•
    """
    os.makedirs(data_dir, exist_ok=True)
    
    # åˆ›å»ºè™šæ‹Ÿæ•°æ®
    rating, features_item, features_user, support_user, support_item, negative = create_dummy_data(10, 5)
    
    # ä¿å­˜ä¸ºæ ·æœ¬æ–‡ä»¶
    sample_files = {
        'sample_rate_matrix.p': rating.numpy(),
        'sample_negative.p': negative.numpy(),
        'sample_UC.p': features_user.numpy(),
        'sample_concept_feature_bow.p': features_item.numpy(),
        'sample_adjacency_matrix.p': support_user[0].numpy() if support_user else np.eye(10)
    }
    
    for filename, data in sample_files.items():
        filepath = os.path.join(data_dir, filename)
        with open(filepath, 'wb') as f:
            pkl.dump(data, f)
        print(f"âœ… ä¿å­˜æ ·æœ¬æ–‡ä»¶: {filepath}")
    
    print(f"ğŸ‰ æ ·æœ¬æ•°æ®å·²ä¿å­˜åˆ° {data_dir}")